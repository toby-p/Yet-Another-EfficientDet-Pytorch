{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GI9KZ3F8TLSK",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# EfficientDet Training On A Custom Dataset\n",
    "\n",
    "\n",
    "\n",
    "<table align=\"left\"><td>\n",
    "  <a target=\"_blank\"  href=\"https://github.com/zylo117/Yet-Another-EfficientDet-Pytorch/blob/master/tutorial/train_logo.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on github\n",
    "  </a>\n",
    "</td><td>\n",
    "  <a target=\"_blank\"  href=\"https://colab.research.google.com/github/zylo117/Yet-Another-EfficientDet-Pytorch/blob/master/tutorial/train_logo.ipynb\">\n",
    "    <img width=32px src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "</td></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67-3S5_VTLSL",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## This tutorial will show you how to train a custom dataset.\n",
    "\n",
    "## Please enable GPU support to accelerate on notebook setting if you are using colab.\n",
    "\n",
    "### 0. Install Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# tesla_dir = \"/workspace/Yet-Another-EfficientDet-Pytorch/projects/datasets/tesla\"\n",
    "# os.path.join(tesla_dir, \"train\")\n",
    "# for f in os.listdir(os.path.join(tesla_dir, \"train\")):\n",
    "#     if f.endswith(\".jpg\"):\n",
    "#         num = int(f[7:].strip(\".jpg\"))\n",
    "#         if num >= 150:\n",
    "#             train_fp = os.path.join(tesla_dir, \"train\", f)\n",
    "#             val_fp = os.path.join(tesla_dir, \"val\", f)\n",
    "#             shutil.move(train_fp, val_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "90laRz20TLSN",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: pycocotools in /opt/conda/lib/python3.8/site-packages (2.0+nv0.6.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (1.22.0)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.8/site-packages (4.5.5.62)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (4.62.3)\n",
      "Requirement already satisfied: tensorboard in /opt/conda/lib/python3.8/site-packages (2.8.0)\n",
      "Requirement already satisfied: tensorboardX in /opt/conda/lib/python3.8/site-packages (2.5)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.8/site-packages (6.0)\n",
      "Requirement already satisfied: webcolors in /opt/conda/lib/python3.8/site-packages (1.11.1)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.8/site-packages (3.5.1)\n",
      "Requirement already satisfied: cython>=0.27.3 in /opt/conda/lib/python3.8/site-packages (from pycocotools) (0.29.26)\n",
      "Requirement already satisfied: setuptools>=18.0 in /opt/conda/lib/python3.8/site-packages (from pycocotools) (59.5.0)\n",
      "Requirement already satisfied: pybind11>=2.2 in /opt/conda/lib/python3.8/site-packages (from pycocotools) (2.9.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.8/site-packages (from tensorboard) (1.43.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard) (3.19.3)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.8/site-packages (from tensorboard) (0.37.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard) (2.26.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.8/site-packages (from tensorboard) (2.4.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard) (1.8.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.8/site-packages (from tensorboard) (2.0.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.8/site-packages (from tensorboard) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.8/site-packages (from tensorboard) (3.3.6)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from tensorboardX) (1.16.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (8.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (3.0.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (4.29.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard) (5.0.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard) (4.10.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.7.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard) (3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard) (2.0.9)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.1.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pycocotools numpy opencv-python tqdm tensorboard tensorboardX pyyaml webcolors matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-R5C4DaETLSS",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1. Prepare Custom Dataset/Pretrained Weights (Skip this part if you already have datasets and weights of your own)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JmCQj3rhTLSS",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'Yet-Another-EfficientDet-Pytorch' already exists and is not an empty directory.\n",
      "mkdir: cannot create directory ‘weights’: File exists\n",
      "--2022-03-07 00:05:26--  https://github.com/zylo117/Yet-Another-EfficientDet-Pytorch/releases/download/1.0/efficientdet-d0.pth\n",
      "Resolving github.com (github.com)... 140.82.113.4\n",
      "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/253385242/9b9d2100-791d-11ea-80b2-d35899cf95fe?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220307%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220307T050526Z&X-Amz-Expires=300&X-Amz-Signature=734284e291975dd11a648fcebc577ed1be3ae6838df0073444b51cc15e7a4cf9&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=253385242&response-content-disposition=attachment%3B%20filename%3Defficientdet-d0.pth&response-content-type=application%2Foctet-stream [following]\n",
      "--2022-03-07 00:05:26--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/253385242/9b9d2100-791d-11ea-80b2-d35899cf95fe?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220307%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220307T050526Z&X-Amz-Expires=300&X-Amz-Signature=734284e291975dd11a648fcebc577ed1be3ae6838df0073444b51cc15e7a4cf9&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=253385242&response-content-disposition=attachment%3B%20filename%3Defficientdet-d0.pth&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 15862583 (15M) [application/octet-stream]\n",
      "Saving to: ‘weights/efficientdet-d0.pth’\n",
      "\n",
      "weights/efficientde 100%[===================>]  15.13M  89.4MB/s    in 0.2s    \n",
      "\n",
      "2022-03-07 00:05:27 (89.4 MB/s) - ‘weights/efficientdet-d0.pth’ saved [15862583/15862583]\n",
      "\n",
      "project_name: tesla  # also the folder name of the dataset that under data_path folder\n",
      "train_set: train\n",
      "val_set: val\n",
      "num_gpus: 1\n",
      "\n",
      "# mean and std in RGB order, actually this part should remain unchanged as long as your dataset is similar to coco.\n",
      "mean: [ 0.485, 0.456, 0.406 ]\n",
      "std: [ 0.229, 0.224, 0.225 ]\n",
      "\n",
      "# this anchor is adapted to the dataset\n",
      "anchors_scales: '[2 ** 0, 2 ** (1.0 / 3.0), 2 ** (2.0 / 3.0)]'\n",
      "anchors_ratios: '[(1.0, 1.0), (1.3, 0.8), (1.9, 0.5)]'\n",
      "\n",
      "obj_list: ['truck', 'car', 'van']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "if \"projects\" not in os.getcwd():\n",
    "  !git clone --depth 1 https://github.com/zylo117/Yet-Another-EfficientDet-Pytorch\n",
    "  os.chdir('Yet-Another-EfficientDet-Pytorch')\n",
    "  sys.path.append('.')\n",
    "else:\n",
    "  !git pull\n",
    "\n",
    "# # download and unzip dataset\n",
    "# ! mkdir datasets\n",
    "# ! wget https://github.com/zylo117/Yet-Another-EfficientDet-Pytorch/releases/download/1.1/dataset_logo.zip\n",
    "# ! unzip -d datasets/ dataset_logo.zip\n",
    "\n",
    "# download pretrained weights\n",
    "! mkdir weights\n",
    "! wget https://github.com/zylo117/Yet-Another-EfficientDet-Pytorch/releases/download/1.0/efficientdet-d0.pth -O weights/efficientdet-d0.pth\n",
    "\n",
    "# prepare project file projects/logo.yml\n",
    "# showing its contents here\n",
    "! cat projects/tesla.yml\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Q2onXNZTLSV"
   },
   "source": [
    "### 2. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a-eznEu5TLSW",
    "outputId": "bba632e4-a7f0-4209-a10a-f801ca6a206b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE! Installing ujson may make loading annotations faster.\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "[Warning] Ignoring Error(s) in loading state_dict for EfficientDetBackbone:\n",
      "\tsize mismatch for classifier.header.pointwise_conv.conv.weight: copying a param with shape torch.Size([810, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([27, 64, 1, 1]).\n",
      "\tsize mismatch for classifier.header.pointwise_conv.conv.bias: copying a param with shape torch.Size([810]) from checkpoint, the shape in current model is torch.Size([27]).\n",
      "[Warning] Don't panic if you see this, this might be because you load a pretrained weights with different number of classes. The rest of the weights should be loaded already.\n",
      "[Info] loaded weights: efficientdet-d0.pth, resuming checkpoint from step: 0\n",
      "[Info] freezed backbone\n",
      "Step: 0. Epoch: 0/10. Iteration: 1/1. Cls loss: 157.78886. Reg loss: 5.91396. To\n",
      "Val. Epoch: 0/10. Classification loss: 82.35687. Regression loss: 4.67411. Total loss: 87.03099\n",
      "Step: 1. Epoch: 1/10. Iteration: 1/1. Cls loss: 92.90338. Reg loss: 4.74450. Tot\n",
      "Val. Epoch: 1/10. Classification loss: 53.46856. Regression loss: 4.41046. Total loss: 57.87902\n",
      "Step: 2. Epoch: 2/10. Iteration: 1/1. Cls loss: 55.89468. Reg loss: 4.37568. Tot\n",
      "Val. Epoch: 2/10. Classification loss: 36.44571. Regression loss: 4.29820. Total loss: 40.74391\n",
      "Step: 3. Epoch: 3/10. Iteration: 1/1. Cls loss: 34.43579. Reg loss: 4.16575. Tot\n",
      "Val. Epoch: 3/10. Classification loss: 21.16541. Regression loss: 4.27804. Total loss: 25.44344\n",
      "Step: 4. Epoch: 4/10. Iteration: 1/1. Cls loss: 20.55157. Reg loss: 4.06611. Tot\n",
      "Val. Epoch: 4/10. Classification loss: 9.82372. Regression loss: 4.27947. Total loss: 14.10319\n",
      "Step: 5. Epoch: 5/10. Iteration: 1/1. Cls loss: 11.46255. Reg loss: 3.97227. Tot\n",
      "Val. Epoch: 5/10. Classification loss: 3.95987. Regression loss: 4.30135. Total loss: 8.26122\n",
      "Step: 6. Epoch: 6/10. Iteration: 1/1. Cls loss: 5.70020. Reg loss: 3.85924. Tota\n",
      "Val. Epoch: 6/10. Classification loss: 2.00694. Regression loss: 4.37818. Total loss: 6.38512\n",
      "Step: 7. Epoch: 7/10. Iteration: 1/1. Cls loss: 2.89617. Reg loss: 3.73829. Tota\n",
      "Val. Epoch: 7/10. Classification loss: 1.41898. Regression loss: 4.57695. Total loss: 5.99593\n",
      "Step: 8. Epoch: 8/10. Iteration: 1/1. Cls loss: 1.62051. Reg loss: 3.69228. Tota\n",
      "Val. Epoch: 8/10. Classification loss: 1.33837. Regression loss: 4.77169. Total loss: 6.11006\n",
      "Step: 9. Epoch: 9/10. Iteration: 1/1. Cls loss: 1.08867. Reg loss: 3.73157. Tota\n",
      "Val. Epoch: 9/10. Classification loss: 1.38687. Regression loss: 4.90248. Total loss: 6.28936\n"
     ]
    }
   ],
   "source": [
    "# consider this is a simple dataset, train head will be enough.\n",
    "! python train.py -c 0 -p tesla --head_only True --lr 5e-3 --batch_size 8 --load_weights weights/efficientdet-d0.pth  --num_epochs 10 --save_interval 100\n",
    "\n",
    "# the loss will be high at first\n",
    "# don't panic, be patient,\n",
    "# just wait for a little bit longer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE! Installing ujson may make loading annotations faster.\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "using weights logs//tesla/efficientdet-d0_49_50.pth\n",
      "[Info] loaded weights: efficientdet-d0_49_50.pth, resuming checkpoint from step: 50\n",
      "Step: 50. Epoch: 50/75. Iteration: 1/1. Cls loss: 0.16802. Reg loss: 1.71516. To\n",
      "Val. Epoch: 50/75. Classification loss: 0.37296. Regression loss: 2.55771. Total loss: 2.93067\n",
      "Step: 51. Epoch: 51/75. Iteration: 1/1. Cls loss: 0.19810. Reg loss: 2.20384. To\n",
      "Val. Epoch: 51/75. Classification loss: 0.30683. Regression loss: 2.55835. Total loss: 2.86518\n",
      "Step: 52. Epoch: 52/75. Iteration: 1/1. Cls loss: 0.16721. Reg loss: 2.04622. To\n",
      "Val. Epoch: 52/75. Classification loss: 0.33655. Regression loss: 2.21660. Total loss: 2.55316\n",
      "Step: 53. Epoch: 53/75. Iteration: 1/1. Cls loss: 0.17329. Reg loss: 1.82497. To\n",
      "Val. Epoch: 53/75. Classification loss: 0.28390. Regression loss: 2.10471. Total loss: 2.38861\n",
      "Step: 54. Epoch: 54/75. Iteration: 1/1. Cls loss: 0.16807. Reg loss: 1.87135. To\n",
      "Epoch     5: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Val. Epoch: 54/75. Classification loss: 0.26136. Regression loss: 2.12059. Total loss: 2.38195\n",
      "Step: 55. Epoch: 55/75. Iteration: 1/1. Cls loss: 0.15454. Reg loss: 1.67719. To\n",
      "Val. Epoch: 55/75. Classification loss: 0.25764. Regression loss: 2.09578. Total loss: 2.35342\n",
      "Step: 56. Epoch: 56/75. Iteration: 1/1. Cls loss: 0.15472. Reg loss: 1.69863. To\n",
      "Val. Epoch: 56/75. Classification loss: 0.25245. Regression loss: 2.05200. Total loss: 2.30445\n",
      "Step: 57. Epoch: 57/75. Iteration: 1/1. Cls loss: 0.15246. Reg loss: 1.61615. To\n",
      "Val. Epoch: 57/75. Classification loss: 0.24657. Regression loss: 1.99842. Total loss: 2.24499\n",
      "Step: 58. Epoch: 58/75. Iteration: 1/1. Cls loss: 0.14915. Reg loss: 1.58819. To\n",
      "Val. Epoch: 58/75. Classification loss: 0.24077. Regression loss: 1.94649. Total loss: 2.18726\n",
      "Step: 59. Epoch: 59/75. Iteration: 1/1. Cls loss: 0.14967. Reg loss: 1.64974. To\n",
      "Val. Epoch: 59/75. Classification loss: 0.23571. Regression loss: 1.90033. Total loss: 2.13603\n",
      "Step: 60. Epoch: 60/75. Iteration: 1/1. Cls loss: 0.14649. Reg loss: 1.59714. To\n",
      "Val. Epoch: 60/75. Classification loss: 0.23154. Regression loss: 1.86359. Total loss: 2.09513\n",
      "Step: 61. Epoch: 61/75. Iteration: 1/1. Cls loss: 0.14222. Reg loss: 1.49133. To\n",
      "Val. Epoch: 61/75. Classification loss: 0.22833. Regression loss: 1.83327. Total loss: 2.06160\n",
      "Step: 62. Epoch: 62/75. Iteration: 1/1. Cls loss: 0.13721. Reg loss: 1.51462. To\n",
      "Val. Epoch: 62/75. Classification loss: 0.22570. Regression loss: 1.80821. Total loss: 2.03390\n",
      "Step: 63. Epoch: 63/75. Iteration: 1/1. Cls loss: 0.13834. Reg loss: 1.50385. To\n",
      "Val. Epoch: 63/75. Classification loss: 0.22357. Regression loss: 1.78806. Total loss: 2.01163\n",
      "Step: 64. Epoch: 64/75. Iteration: 1/1. Cls loss: 0.13377. Reg loss: 1.43321. To\n",
      "Val. Epoch: 64/75. Classification loss: 0.22160. Regression loss: 1.76921. Total loss: 1.99081\n",
      "Step: 65. Epoch: 65/75. Iteration: 1/1. Cls loss: 0.13699. Reg loss: 1.52533. To\n",
      "Val. Epoch: 65/75. Classification loss: 0.21936. Regression loss: 1.75225. Total loss: 1.97162\n",
      "Step: 66. Epoch: 66/75. Iteration: 1/1. Cls loss: 0.13257. Reg loss: 1.44920. To\n",
      "Val. Epoch: 66/75. Classification loss: 0.21697. Regression loss: 1.73746. Total loss: 1.95443\n",
      "Step: 67. Epoch: 67/75. Iteration: 1/1. Cls loss: 0.13499. Reg loss: 1.49948. To\n",
      "Val. Epoch: 67/75. Classification loss: 0.21406. Regression loss: 1.72329. Total loss: 1.93735\n",
      "Step: 68. Epoch: 68/75. Iteration: 1/1. Cls loss: 0.13449. Reg loss: 1.47691. To\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Val. Epoch: 68/75. Classification loss: 0.21092. Regression loss: 1.70966. Total loss: 1.92058\n",
      "Step: 69. Epoch: 69/75. Iteration: 1/1. Cls loss: 0.13100. Reg loss: 1.40671. To\n",
      "Val. Epoch: 69/75. Classification loss: 0.20878. Regression loss: 1.70161. Total loss: 1.91039\n",
      "Step: 70. Epoch: 70/75. Iteration: 1/1. Cls loss: 0.12969. Reg loss: 1.41153. To\n",
      "Val. Epoch: 70/75. Classification loss: 0.20670. Regression loss: 1.69375. Total loss: 1.90045\n",
      "Step: 71. Epoch: 71/75. Iteration: 1/1. Cls loss: 0.13143. Reg loss: 1.43527. To\n",
      "Val. Epoch: 71/75. Classification loss: 0.20463. Regression loss: 1.68602. Total loss: 1.89066\n",
      "Step: 72. Epoch: 72/75. Iteration: 1/1. Cls loss: 0.12642. Reg loss: 1.37709. To\n",
      "Val. Epoch: 72/75. Classification loss: 0.20263. Regression loss: 1.67786. Total loss: 1.88049\n",
      "Step: 73. Epoch: 73/75. Iteration: 1/1. Cls loss: 0.13195. Reg loss: 1.44579. To\n",
      "Val. Epoch: 73/75. Classification loss: 0.20061. Regression loss: 1.67014. Total loss: 1.87075\n",
      "Step: 74. Epoch: 74/75. Iteration: 1/1. Cls loss: 0.13397. Reg loss: 1.42809. To\n",
      "Val. Epoch: 74/75. Classification loss: 0.19869. Regression loss: 1.66269. Total loss: 1.86137\n"
     ]
    }
   ],
   "source": [
    "! python train.py -c 0 -p tesla --head_only False --lr 1e-3 --batch_size 8 --load_weights last --num_epochs 75 --save_interval 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "05mjrGRETLSZ"
   },
   "source": [
    "### 3. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9yzNyaSxTLSZ",
    "outputId": "642e7fca-e729-40b0-82a7-aa466820bd9e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/Yet-Another-EfficientDet-Pytorch/tutorial/Yet-Another-EfficientDet-Pytorch/logs/tesla\n",
      "/workspace/Yet-Another-EfficientDet-Pytorch/tutorial/Yet-Another-EfficientDet-Pytorch\n",
      "NOTE! Installing ujson may make loading annotations faster.\n",
      "running coco-style evaluation on project tesla, weights logs/tesla/efficientdet-d0_74_75.pth...\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:02<00:00,  3.29it/s]\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "BBox\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.96s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.03s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.13550\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.29556\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.11239\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.00000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.07035\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.16962\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.02318\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.11472\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.20659\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.00000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.16070\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.23789\n"
     ]
    }
   ],
   "source": [
    "#get latest weight file\n",
    "%cd logs/tesla\n",
    "weight_file = !ls -Art | grep efficientdet\n",
    "%cd ../..\n",
    "\n",
    "#uncomment the next line to specify a weight file\n",
    "weight_file[-1] = 'efficientdet-d0_74_75.pth'\n",
    "\n",
    "! python coco_eval.py -c 0 -p tesla -w \"logs/tesla/{weight_file[-1]}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zhV3bNF3TLSc",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 4. Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "uEDHMAIJTLSc",
    "outputId": "a9b31282-e4eb-444b-bb83-a39cb8d99574",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.backends import cudnn\n",
    "\n",
    "from backbone import EfficientDetBackbone\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from efficientdet.utils import BBoxTransform, ClipBoxes\n",
    "from utils.utils import preprocess, invert_affine, postprocess\n",
    "\n",
    "compound_coef = 0\n",
    "force_input_size = None  # set None to use default size\n",
    "img_path = 'datasets/tesla/val/tesla0_00150.jpg'\n",
    "\n",
    "threshold = 0.2\n",
    "iou_threshold = 0.2\n",
    "\n",
    "use_cuda = True\n",
    "use_float16 = False\n",
    "cudnn.fastest = True\n",
    "cudnn.benchmark = True\n",
    "\n",
    "obj_list = [ 'truck', 'car', 'van' ]\n",
    "\n",
    "# tf bilinear interpolation is different from any other's, just make do\n",
    "input_sizes = [512, 640, 768, 896, 1024, 1280, 1280, 1536]\n",
    "input_size = input_sizes[compound_coef] if force_input_size is None else force_input_size\n",
    "ori_imgs, framed_imgs, framed_metas = preprocess(img_path, max_size=input_size)\n",
    "\n",
    "if use_cuda:\n",
    "    x = torch.stack([torch.from_numpy(fi).cuda() for fi in framed_imgs], 0)\n",
    "else:\n",
    "    x = torch.stack([torch.from_numpy(fi) for fi in framed_imgs], 0)\n",
    "\n",
    "x = x.to(torch.float32 if not use_float16 else torch.float16).permute(0, 3, 1, 2)\n",
    "\n",
    "model = EfficientDetBackbone(compound_coef=compound_coef, num_classes=len(obj_list),\n",
    "\n",
    "                             # replace this part with your project's anchor config\n",
    "                             ratios=[(1.0, 1.0), (1.3, 0.8), (1.9, 0.5)],\n",
    "                             scales=[2 ** 0, 2 ** (1.0 / 3.0), 2 ** (2.0 / 3.0)])\n",
    "\n",
    "model.load_state_dict(torch.load('logs/tesla/'+weight_file[-1]))\n",
    "model.requires_grad_(False)\n",
    "model.eval()\n",
    "\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "if use_float16:\n",
    "    model = model.half()\n",
    "\n",
    "with torch.no_grad():\n",
    "    features, regression, classification, anchors = model(x)\n",
    "\n",
    "    regressBoxes = BBoxTransform()\n",
    "    clipBoxes = ClipBoxes()\n",
    "\n",
    "    out = postprocess(x,\n",
    "                      anchors, regression, classification,\n",
    "                      regressBoxes, clipBoxes,\n",
    "                      threshold, iou_threshold)\n",
    "\n",
    "out = invert_affine(framed_metas, out)\n",
    "\n",
    "for i in range(len(ori_imgs)):\n",
    "    if len(out[i]['rois']) == 0:\n",
    "        continue\n",
    "    ori_imgs[i] = ori_imgs[i].copy()\n",
    "    for j in range(len(out[i]['rois'])):\n",
    "        (x1, y1, x2, y2) = out[i]['rois'][j].astype(np.int)\n",
    "        cv2.rectangle(ori_imgs[i], (x1, y1), (x2, y2), (255, 255, 0), 2)\n",
    "        obj = obj_list[out[i]['class_ids'][j]]\n",
    "        score = float(out[i]['scores'][j])\n",
    "\n",
    "        cv2.putText(ori_imgs[i], '{}, {:.3f}'.format(obj, score),\n",
    "                    (x1, y1 + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                    (255, 255, 0), 1)\n",
    "\n",
    "        plt.imshow(ori_imgs[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "train_shape.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
